{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to Hyperion The special task processing tool Main goals For the main goals and the current progress please have a look at current Milestone 1.0.0 . You can see there which issues are closed and which ones are in the queue. The list of open issues is not necessarily complete, it means there might be further features added to that milestone. Status The tool is not yet production ready. I cannot tell you a release date the moment, but I'm constantly developing on it in my free time. The current issue(s) I'm working on are pinned and can be seen at the top of the issue list. Issues If you are using the tool and find things please report an issue but please check before that the issue isn't already there. The issue tracker is here . Please do not assign tags (please leave that to me). Thank you. Please also provide concrete examples that I'm able to reproduce the problem. Documentation The current documentation will be here . Have a look at the top menu under menu entry Index . As mentioned the tool is not yet production ready - so please be patient - there will be detailed documentation and examples.","title":"Home"},{"location":"#welcome-to-hyperion","text":"The special task processing tool","title":"Welcome to Hyperion"},{"location":"#main-goals","text":"For the main goals and the current progress please have a look at current Milestone 1.0.0 . You can see there which issues are closed and which ones are in the queue. The list of open issues is not necessarily complete, it means there might be further features added to that milestone.","title":"Main goals"},{"location":"#status","text":"The tool is not yet production ready. I cannot tell you a release date the moment, but I'm constantly developing on it in my free time. The current issue(s) I'm working on are pinned and can be seen at the top of the issue list.","title":"Status"},{"location":"#issues","text":"If you are using the tool and find things please report an issue but please check before that the issue isn't already there. The issue tracker is here . Please do not assign tags (please leave that to me). Thank you. Please also provide concrete examples that I'm able to reproduce the problem.","title":"Issues"},{"location":"#documentation","text":"The current documentation will be here . Have a look at the top menu under menu entry Index . As mentioned the tool is not yet production ready - so please be patient - there will be detailed documentation and examples.","title":"Documentation"},{"location":"build/","text":"Build Quick and easy The build is organized with Maven. You don't have to install Maven because Maven Wrapper ( https://github.com/takari/maven-wrapper ) is used. On any system following command is sufficient as long as Java is given ( minimum Version : 11): ./mvnw On Unix based systems this is the exact filename of the script that is executed. On Windows it's the mvnw.cmd script (anyway you do not have to specify the extension that's why it looks and feel identical on all systems). Maven Profiles There are two profiles; one for Windows and one for Unix based systems. The main reason for two profiles is that the code coverage is different since not every test can be executed on every system (example: The UnixShellTaskTest can run on Unix based systems only). The reason to use a profile in general is to be able to define default goals, so you do not have to specify them on command line each time (convenience reason). Default goals The default goals are: clean package javadoc:jar verify clean - removes the target folder package - includes all previous goals like resource filtering, compiling and running tests. The package is combining the concrete jar with all dependencies into one jar that allows to use it standalone. javadoc:jar - generate the Javadoc HTML documentation and the javadoc jar. verify - is running all static code analysis (including the analysis of the code coverage). Maven Dependencies Test dependencies Those dependencies are available only while testing. Dependency Homepage License Usage org.junit.jupiter:junit-jupiter-api:5.5.2 https://junit.org/junit5/ Eclipse Public License - v 2.0 Unittests org.junit.jupiter:junit-jupiter-engine:5.5.2 https://junit.org/junit5/ Eclipse Public License - v 2.0 Unittests org.junit.jupiter:junit-jupiter-params:5.5.2 https://junit.org/junit5/ Eclipse Public License - v 2.0 Unittests Runtime dependencies Those dependencies are required at runtime and taken by the Maven shade plugin when packaging. Dependency Homepage License Usage com.fasterxml.jackson.dataformat:jackson-dataformat-yaml:2.12.1 https://github.com/FasterXML/jackson Eclipse Public License 2.0 Reading YAML files ch.qos.logback:logback-classic:1.2.3 http://logback.qos.ch/ Logback License Logging org.apache.commons:commons-lang3:3.12:0 https://commons.apache.org/proper/commons-lang/ Apache License 2.0 Tool classes io.pebbletemplates:pebble:3.1.5 https://pebbletemplates.io/ Pebble License Template Engine org.codehaus.groovy:groovy:3.0.7 http://www.groovy-lang.org/ Apache 2.0 License Embedded Language for GroovyTask Build dependencies Those dependencies are required while building only. Dependency Homepage License Usage pl.project13.maven:git-commit-id-plugin:4.0.0 https://github.com/git-commit-id/git-commit-id-maven-plugin LGPL-3.0 License Providing Git Information for resource filtering org.apache.maven.plugins:maven-compiler-plugin:3.8.0 https://maven.apache.org/plugins/maven-compiler-plugin/ Apache License. 2.0 Compiling Java code org.apache.maven.plugins:maven-surefire-plugin:3.0.0-M5 https://maven.apache.org/surefire/maven-surefire-plugin/ Apache License. 2.0 Running tests org.jacoco:jacoco-maven-plugin:0.8.6 https://www.jacoco.org/jacoco/trunk/doc/maven.html EPL 2.0 Code coverage analysis org.apache.maven.plugins:maven-checkstyle-plugin:3.1.2 https://maven.apache.org/plugins/maven-checkstyle-plugin/ Apache License. 2.0 Static coded analysis com.github.spotbugs:spotbugs-maven-plugin:4.1.3 https://spotbugs.github.io/spotbugs-maven-plugin/ Apache License, 2.0 Static coded analysis org.apache.maven.plugins:maven-pmd-plugin:3.14.0 https://maven.apache.org/plugins/maven-dependency-plugin/ Apache License. 2.0 Static code analysis org.apache.maven.plugins:maven-shade-plugin:3.2.4 https://maven.apache.org/plugins/maven-shade-plugin/ Apache License. 2.0 All in one jar generator org.apache.maven.plugins:maven-javadoc-plugin:3.2.0 http://maven.apache.org/plugins/maven-javadoc-plugin/ Apache License. 2.0 API Documentation tool org.apache.maven.plugins:maven-dependency-plugin:3.1.2 https://maven.apache.org/plugins/maven-dependency-plugin/ Apache License. 2.0 Maven dependencies tool Test configuration The configuration of the surefire Maven plugin is the scope here: The configuration option <runOrder>random</runOrder> ensures that tests classes are running in random order. There is another very special configuration I don't like much but found it somewhere on the internet to handle the output on Console as well as the XML. They Junit5 guys did somehow a break in the format of the JUnit XML and you have to configure that it somehow works for current tools. Please don't ask me for details. Simply copy the configuration or leave it or find another solution on internet (I doubt you find much more than I habe found). Github actions It's surprisingly easy to organize a build for all three platforms and multiple Java versions with Github actions. The build is written in YAML format and is called workflow . Workflows have to be located at .github/workflows. The workflow for Hyperion is in the file .github/workflows/hyperion-build-actions.yml . Each time you push your changes remote the workflow automatically starts. The success is then visible by an success/failure icon on each location where the commit is shown. The history for all actions (including the currently running one) you can find here: https://github.com/thomas-lehmann-private/hyperion/actions . The file is really simple and the Github actions in general have good documentation. For the code coverage the usage is well documentated by the integration itself. The whole build is organized via a matrix build. All combinations of the values of the existing lists define one build job. When something goes wrong you can read the logs online at the individual build. Please note : The --batch-mode is really important to reduce the verbose output of the download operation for each single artefact. Jenkins You also can run your project locally via Jenkins. You simply create a pipelineline specifying the file url to your local repository. You shoudl have some plugins installed like Jacoco , Javadoc , AnsiColor , Built Timeout , Green Balls and Workspace Cleanup . The Jenkins job presents you out-of-the-box trend graphs for your tests, the code coverage and the static code analyses. Very awesome. The Jenkinsfile (default when you create a pipeline job) is given in the repository. I hope you agree: It's a small file. How to handle things In general violations will break the build, and the common expectation is that issues are correctly resolved. When a Jacoco error is raised it does mean that you have added coded without testing it. Decreasing the limit is not acceptable. When your code coverage does get better please increase those limits. When Checkstyle , PMD or Spotbug raise an error for src/main/java the expectation is to fix it without any suppression in 99% of all cases. For the 1% where you think you have to suppress it the reason has to be well documented. For some sort of error like magic numbers or repeated string literals happening in Unittests it's mostly ok when you use suppression. It should never happen that the code is overwhelmed with suppression. Interesting Links https://docs.github.com/en/actions https://github.com/actions/virtual-environments https://www.jenkins.io/doc/book/pipeline/syntax https://github.com/takari/maven-wrapper https://docs.github.com/en/actions/guides https://github.com/marketplace/actions/deploy-to-github-pages","title":"Build"},{"location":"build/#build","text":"","title":"Build"},{"location":"build/#quick-and-easy","text":"The build is organized with Maven. You don't have to install Maven because Maven Wrapper ( https://github.com/takari/maven-wrapper ) is used. On any system following command is sufficient as long as Java is given ( minimum Version : 11): ./mvnw On Unix based systems this is the exact filename of the script that is executed. On Windows it's the mvnw.cmd script (anyway you do not have to specify the extension that's why it looks and feel identical on all systems).","title":"Quick and easy"},{"location":"build/#maven-profiles","text":"There are two profiles; one for Windows and one for Unix based systems. The main reason for two profiles is that the code coverage is different since not every test can be executed on every system (example: The UnixShellTaskTest can run on Unix based systems only). The reason to use a profile in general is to be able to define default goals, so you do not have to specify them on command line each time (convenience reason).","title":"Maven Profiles"},{"location":"build/#default-goals","text":"The default goals are: clean package javadoc:jar verify clean - removes the target folder package - includes all previous goals like resource filtering, compiling and running tests. The package is combining the concrete jar with all dependencies into one jar that allows to use it standalone. javadoc:jar - generate the Javadoc HTML documentation and the javadoc jar. verify - is running all static code analysis (including the analysis of the code coverage).","title":"Default goals"},{"location":"build/#maven-dependencies","text":"","title":"Maven Dependencies"},{"location":"build/#test-dependencies","text":"Those dependencies are available only while testing. Dependency Homepage License Usage org.junit.jupiter:junit-jupiter-api:5.5.2 https://junit.org/junit5/ Eclipse Public License - v 2.0 Unittests org.junit.jupiter:junit-jupiter-engine:5.5.2 https://junit.org/junit5/ Eclipse Public License - v 2.0 Unittests org.junit.jupiter:junit-jupiter-params:5.5.2 https://junit.org/junit5/ Eclipse Public License - v 2.0 Unittests","title":"Test dependencies"},{"location":"build/#runtime-dependencies","text":"Those dependencies are required at runtime and taken by the Maven shade plugin when packaging. Dependency Homepage License Usage com.fasterxml.jackson.dataformat:jackson-dataformat-yaml:2.12.1 https://github.com/FasterXML/jackson Eclipse Public License 2.0 Reading YAML files ch.qos.logback:logback-classic:1.2.3 http://logback.qos.ch/ Logback License Logging org.apache.commons:commons-lang3:3.12:0 https://commons.apache.org/proper/commons-lang/ Apache License 2.0 Tool classes io.pebbletemplates:pebble:3.1.5 https://pebbletemplates.io/ Pebble License Template Engine org.codehaus.groovy:groovy:3.0.7 http://www.groovy-lang.org/ Apache 2.0 License Embedded Language for GroovyTask","title":"Runtime dependencies"},{"location":"build/#build-dependencies","text":"Those dependencies are required while building only. Dependency Homepage License Usage pl.project13.maven:git-commit-id-plugin:4.0.0 https://github.com/git-commit-id/git-commit-id-maven-plugin LGPL-3.0 License Providing Git Information for resource filtering org.apache.maven.plugins:maven-compiler-plugin:3.8.0 https://maven.apache.org/plugins/maven-compiler-plugin/ Apache License. 2.0 Compiling Java code org.apache.maven.plugins:maven-surefire-plugin:3.0.0-M5 https://maven.apache.org/surefire/maven-surefire-plugin/ Apache License. 2.0 Running tests org.jacoco:jacoco-maven-plugin:0.8.6 https://www.jacoco.org/jacoco/trunk/doc/maven.html EPL 2.0 Code coverage analysis org.apache.maven.plugins:maven-checkstyle-plugin:3.1.2 https://maven.apache.org/plugins/maven-checkstyle-plugin/ Apache License. 2.0 Static coded analysis com.github.spotbugs:spotbugs-maven-plugin:4.1.3 https://spotbugs.github.io/spotbugs-maven-plugin/ Apache License, 2.0 Static coded analysis org.apache.maven.plugins:maven-pmd-plugin:3.14.0 https://maven.apache.org/plugins/maven-dependency-plugin/ Apache License. 2.0 Static code analysis org.apache.maven.plugins:maven-shade-plugin:3.2.4 https://maven.apache.org/plugins/maven-shade-plugin/ Apache License. 2.0 All in one jar generator org.apache.maven.plugins:maven-javadoc-plugin:3.2.0 http://maven.apache.org/plugins/maven-javadoc-plugin/ Apache License. 2.0 API Documentation tool org.apache.maven.plugins:maven-dependency-plugin:3.1.2 https://maven.apache.org/plugins/maven-dependency-plugin/ Apache License. 2.0 Maven dependencies tool","title":"Build dependencies"},{"location":"build/#test-configuration","text":"The configuration of the surefire Maven plugin is the scope here: The configuration option <runOrder>random</runOrder> ensures that tests classes are running in random order. There is another very special configuration I don't like much but found it somewhere on the internet to handle the output on Console as well as the XML. They Junit5 guys did somehow a break in the format of the JUnit XML and you have to configure that it somehow works for current tools. Please don't ask me for details. Simply copy the configuration or leave it or find another solution on internet (I doubt you find much more than I habe found).","title":"Test configuration"},{"location":"build/#github-actions","text":"It's surprisingly easy to organize a build for all three platforms and multiple Java versions with Github actions. The build is written in YAML format and is called workflow . Workflows have to be located at .github/workflows. The workflow for Hyperion is in the file .github/workflows/hyperion-build-actions.yml . Each time you push your changes remote the workflow automatically starts. The success is then visible by an success/failure icon on each location where the commit is shown. The history for all actions (including the currently running one) you can find here: https://github.com/thomas-lehmann-private/hyperion/actions . The file is really simple and the Github actions in general have good documentation. For the code coverage the usage is well documentated by the integration itself. The whole build is organized via a matrix build. All combinations of the values of the existing lists define one build job. When something goes wrong you can read the logs online at the individual build. Please note : The --batch-mode is really important to reduce the verbose output of the download operation for each single artefact.","title":"Github actions"},{"location":"build/#jenkins","text":"You also can run your project locally via Jenkins. You simply create a pipelineline specifying the file url to your local repository. You shoudl have some plugins installed like Jacoco , Javadoc , AnsiColor , Built Timeout , Green Balls and Workspace Cleanup . The Jenkins job presents you out-of-the-box trend graphs for your tests, the code coverage and the static code analyses. Very awesome. The Jenkinsfile (default when you create a pipeline job) is given in the repository. I hope you agree: It's a small file.","title":"Jenkins"},{"location":"build/#how-to-handle-things","text":"In general violations will break the build, and the common expectation is that issues are correctly resolved. When a Jacoco error is raised it does mean that you have added coded without testing it. Decreasing the limit is not acceptable. When your code coverage does get better please increase those limits. When Checkstyle , PMD or Spotbug raise an error for src/main/java the expectation is to fix it without any suppression in 99% of all cases. For the 1% where you think you have to suppress it the reason has to be well documented. For some sort of error like magic numbers or repeated string literals happening in Unittests it's mostly ok when you use suppression. It should never happen that the code is overwhelmed with suppression.","title":"How to handle things"},{"location":"build/#interesting-links","text":"https://docs.github.com/en/actions https://github.com/actions/virtual-environments https://www.jenkins.io/doc/book/pipeline/syntax https://github.com/takari/maven-wrapper https://docs.github.com/en/actions/guides https://github.com/marketplace/actions/deploy-to-github-pages","title":"Interesting Links"},{"location":"cli/","text":"CLI In future the code might move to an own individual respository. Nevertheless it should be documented how it works... Defining an option The creation of an option is best explained by an example: final var option = CliOption.builder() .setLongName(\"file\") .setShortName(\"f\") .setDescription(\"Provide document to process\") .setType(OptionType.STRING) .setRequired(true) .setRepeatable(false) .build(); The build() will throw an CliException when the validation of your definition has failed. Long names The field is required. A long name has to be lower case. You can combine as maximum three so called sub names namea-nameb-namec by dashes. Each subname has to start with a letter; then also numbers may be used (no other characters). it's not allowed to have less than 2 characters and no more than 15 characters. You can use the long name in two forms: --name=value --name value Short names The field is option (null or empty counts as not set). A short name can be upper case or lower case. You are allowed to define one character only (length equal to 1). You can use the short name in two forms: -v1234 -v 1234 Description The field is required It cannot be null and also not be empty The length may not exceed 40 characters. Keep in mind that this description should help the user. Repeatable The default is false (not repeatable). A repeatable option means that under given name a list of values is stored. The repeatable flag is shown in the help. Required The default is false (not required). A required field means that you have to specify the parameter. The required flag is shown in the help. Special scenario : consider a --help (which should be optional). If you (as an example) specify the option --file as required the CliParser will throw a CliException if you just use --help. You can define a command and with such an option (example: run). Only if you use that command you also have to specify the required option. Type The types are boolean, string, integer, double and path (for now). The default is string. The boolean means that you don't expect a value. The types are currently used for the help only to show what value is expected. Validation The build() function checks the rules as described before throwing a CliException when validation has failed. Defining a command The creation of a command is working pretty the same way as for the options. The definition of the command options is exactly the same thing. final var command = CliCommand.builder() .setName(\"run\") .setDescription(\"processing a document with tasks\") .addOption(fileOption) .build(); Name The name is required. The name should have at least two characters, and the length must not exceed 10 characters. The name has to be lower case. Description The field is required It cannot be null and also not be empty Option you can call addOption (several times) to add one option. you can call addAllOption (several times) to add a list of options. Validation The build() function checks the rules as described below throwing a CliException when validation has failed. checking for name and description checking for options a long name may exist once only a short name may exist once only a description may exist once only The option list The option list (CliOptionList) is special class keeping a list of options working with the builder options as already seen for the other classes. The build() function finally does also the validation: a long name may exist once only a short name may exist once only a description may exist once only These option list is required for the parser. Using the parser The parser does parse the command line arguments. final var parser = CliParser.builder() .setGlobalOptions(globalOptions) .setCommands(commands) .build(); final var result = parser.parse(arguments); Global options You set the list of global options (see option list - CliOptionList). Commands You have two options: using setCommands to set a list of commands (old commands are lost). using addCommand (several times) to add one command. Validation when parsing While parsing the command line arguments further validation is done: required options that are missing repeated options that are not defined repeatable if you use more than once command unknown options unknown commands Please note : You have to use global options before any command If you want to use required options don't use them on global options otherwise you run into problems when trying to use --help (as an example). Simply define a command for it. Using the result When the parsing is fine you get an instance of type CliResult and you three information are available then: with getGlobalOptions() you get a map where the key is the long name of the option the value is a list; if the option is repeatable it contains more than one value. same for getCommandOptions() . with getCommandName() you get the command. It's on you how you handle it. Help printer The setup of the help printer works similar as the parser. In addition to the defined options and commands you specify the execution, the product version, the build timestamp and the author: private void printHelp() throws CliException { final var helpPrinter = CliHelpPrinter.builder() .setExecution(\"java -jar \" + this.properties.getProperty(PROPERTY_FINAL_NAME) + \".jar\") .setProductVersion(this.properties.getProperty(PROPERTY_PRODUCT_VERSION)) .setBuildTimestamp(this.properties.getProperty(PROPERTY_BUILD_TIMESTAMP)) .setAuthor(this.properties.getProperty(PROPERTY_AUTHOR)) .setGlobalOptions(this.globalOptions) .setCommands(this.commands) .build(); helpPrinter.print(LoggerFactory.getLogger(\"HELP\")::info); } The code is extracted from the Hyperion application as I'm using it iself. With Maven and resource filtering I'm passing the information like the final name of the jar, the product version, the build timestamp and the author. For the logging I'm using a custom logger to avoid the usually timestamped output. At the time when I'm writing this documentation the result did look like following: java -jar hyperion-1.0.0-SNAPSHOT.jar [global options] [command [command options]] version: 1.0.0-SNAPSHOT, build timestamp: 2021-05-14 15:21 author: Thomas Lehmann <thomas.lehmann.private@gmail.com> Global options: -h, --help - displaying this help --third-party - displaying used 3rd party libraries List of available commands: run - Running one document with tasks to be processed Options for command 'run': -f<path>, --file=<path> - Document with tasks to be processed [required]","title":"CLI"},{"location":"cli/#cli","text":"In future the code might move to an own individual respository. Nevertheless it should be documented how it works...","title":"CLI"},{"location":"cli/#defining-an-option","text":"The creation of an option is best explained by an example: final var option = CliOption.builder() .setLongName(\"file\") .setShortName(\"f\") .setDescription(\"Provide document to process\") .setType(OptionType.STRING) .setRequired(true) .setRepeatable(false) .build(); The build() will throw an CliException when the validation of your definition has failed.","title":"Defining an option"},{"location":"cli/#long-names","text":"The field is required. A long name has to be lower case. You can combine as maximum three so called sub names namea-nameb-namec by dashes. Each subname has to start with a letter; then also numbers may be used (no other characters). it's not allowed to have less than 2 characters and no more than 15 characters. You can use the long name in two forms: --name=value --name value","title":"Long names"},{"location":"cli/#short-names","text":"The field is option (null or empty counts as not set). A short name can be upper case or lower case. You are allowed to define one character only (length equal to 1). You can use the short name in two forms: -v1234 -v 1234","title":"Short names"},{"location":"cli/#description","text":"The field is required It cannot be null and also not be empty The length may not exceed 40 characters. Keep in mind that this description should help the user.","title":"Description"},{"location":"cli/#repeatable","text":"The default is false (not repeatable). A repeatable option means that under given name a list of values is stored. The repeatable flag is shown in the help.","title":"Repeatable"},{"location":"cli/#required","text":"The default is false (not required). A required field means that you have to specify the parameter. The required flag is shown in the help. Special scenario : consider a --help (which should be optional). If you (as an example) specify the option --file as required the CliParser will throw a CliException if you just use --help. You can define a command and with such an option (example: run). Only if you use that command you also have to specify the required option.","title":"Required"},{"location":"cli/#type","text":"The types are boolean, string, integer, double and path (for now). The default is string. The boolean means that you don't expect a value. The types are currently used for the help only to show what value is expected.","title":"Type"},{"location":"cli/#validation","text":"The build() function checks the rules as described before throwing a CliException when validation has failed.","title":"Validation"},{"location":"cli/#defining-a-command","text":"The creation of a command is working pretty the same way as for the options. The definition of the command options is exactly the same thing. final var command = CliCommand.builder() .setName(\"run\") .setDescription(\"processing a document with tasks\") .addOption(fileOption) .build();","title":"Defining a command"},{"location":"cli/#name","text":"The name is required. The name should have at least two characters, and the length must not exceed 10 characters. The name has to be lower case.","title":"Name"},{"location":"cli/#description_1","text":"The field is required It cannot be null and also not be empty","title":"Description"},{"location":"cli/#option","text":"you can call addOption (several times) to add one option. you can call addAllOption (several times) to add a list of options.","title":"Option"},{"location":"cli/#validation_1","text":"The build() function checks the rules as described below throwing a CliException when validation has failed. checking for name and description checking for options a long name may exist once only a short name may exist once only a description may exist once only","title":"Validation"},{"location":"cli/#the-option-list","text":"The option list (CliOptionList) is special class keeping a list of options working with the builder options as already seen for the other classes. The build() function finally does also the validation: a long name may exist once only a short name may exist once only a description may exist once only These option list is required for the parser.","title":"The option list"},{"location":"cli/#using-the-parser","text":"The parser does parse the command line arguments. final var parser = CliParser.builder() .setGlobalOptions(globalOptions) .setCommands(commands) .build(); final var result = parser.parse(arguments);","title":"Using the parser"},{"location":"cli/#global-options","text":"You set the list of global options (see option list - CliOptionList).","title":"Global options"},{"location":"cli/#commands","text":"You have two options: using setCommands to set a list of commands (old commands are lost). using addCommand (several times) to add one command.","title":"Commands"},{"location":"cli/#validation-when-parsing","text":"While parsing the command line arguments further validation is done: required options that are missing repeated options that are not defined repeatable if you use more than once command unknown options unknown commands Please note : You have to use global options before any command If you want to use required options don't use them on global options otherwise you run into problems when trying to use --help (as an example). Simply define a command for it.","title":"Validation when parsing"},{"location":"cli/#using-the-result","text":"When the parsing is fine you get an instance of type CliResult and you three information are available then: with getGlobalOptions() you get a map where the key is the long name of the option the value is a list; if the option is repeatable it contains more than one value. same for getCommandOptions() . with getCommandName() you get the command. It's on you how you handle it.","title":"Using the result"},{"location":"cli/#help-printer","text":"The setup of the help printer works similar as the parser. In addition to the defined options and commands you specify the execution, the product version, the build timestamp and the author: private void printHelp() throws CliException { final var helpPrinter = CliHelpPrinter.builder() .setExecution(\"java -jar \" + this.properties.getProperty(PROPERTY_FINAL_NAME) + \".jar\") .setProductVersion(this.properties.getProperty(PROPERTY_PRODUCT_VERSION)) .setBuildTimestamp(this.properties.getProperty(PROPERTY_BUILD_TIMESTAMP)) .setAuthor(this.properties.getProperty(PROPERTY_AUTHOR)) .setGlobalOptions(this.globalOptions) .setCommands(this.commands) .build(); helpPrinter.print(LoggerFactory.getLogger(\"HELP\")::info); } The code is extracted from the Hyperion application as I'm using it iself. With Maven and resource filtering I'm passing the information like the final name of the jar, the product version, the build timestamp and the author. For the logging I'm using a custom logger to avoid the usually timestamped output. At the time when I'm writing this documentation the result did look like following: java -jar hyperion-1.0.0-SNAPSHOT.jar [global options] [command [command options]] version: 1.0.0-SNAPSHOT, build timestamp: 2021-05-14 15:21 author: Thomas Lehmann <thomas.lehmann.private@gmail.com> Global options: -h, --help - displaying this help --third-party - displaying used 3rd party libraries List of available commands: run - Running one document with tasks to be processed Options for command 'run': -f<path>, --file=<path> - Document with tasks to be processed [required]","title":"Help printer"},{"location":"docker-container/","text":"Docker container task This doesn't intend to explain Docker. Please refer to official Docker documentation for details on it. It's about the Docker container task. However a few things to mention here: Docker is an external tool that must exist otherwise you cannot use the task; even more the Hyperion tool will throw an error when the Docker tool has not been found. The default is to run Docker container with Unix images. On Windows you are able to switch to Windows container so you could run Windows batch code inside the Docker container. Usually you can switch to either use the one paltform or the other platform but not both at same time. From documentation, it seems an experimental feature that can be turned on allowing you to specify the parameter --platform with the values windows or unix so you could use both at same time. Since it is experimental and I cannot rely on yet that this is turned on by default I don't generate that parameter; means you cannot use both at same time for now. Also on Windows you have to be aware that sharing a drive is to be adjusted in the settings of Docker. Be aware that right now Hyperion differs two mounts which are currently done automatically: the mount of the current working directory (as /work) the mount of the path usually used for generating temporary files and folders by the standard Java API. At least it means you might have to allow more than one Windows drive to be shared with the Docker container . Since you probably want to run Hyperion processing automatically it is advisable to adjust this in advance otherwise the Docker process is trying to ask you via Dialog. The minimal example It's really easy and doesn't differ much from other task. Following details: The parameter image-name is required and should be the name of the Docker image. The parameter imager-version is optional and should be the version of the Docker image. If not specified the version is set to latest . The parameter platform is optional and can be either windows or unix . If not specified the platform is set to unix . It does have the effect that the generated temporary script - that will be executed by the Docker container - is either passed to cmd /c or sh -c . As already mentioned you cannot use both platforms in one document since --platform is not yet generated. So you have to decide which platform Docker should use by switching to it manually. Once the experimental status goes away that might change. --- taskgroups: - title: test tasks: - type: docker-container code: echo \"hello world!\" image-name: debian Minimal example with tags The application can be called with the repeatable option --tag. Specifying the those filter task will be executed only contain those tags. Task with other tags or even without any tags will be ignored then. --- taskgroups: - title: test tasks: - type: docker-container code: echo \"hello world!\" image-name: debian tags: - simple - example Example with variable The example with variable shows how to use the variable to extract information. It's exactly the same way as it does work for other tasks. You can specify the regex for filtering and - if required - the regex group; the default group is 0. --- taskgroups: - title: test tasks: - type: docker-container title: a simple example code: echo \"---> this is a demo <---\" image-name: debian variable: name: test2 regex: \">(.*)<\" group: 1 Example with templating The task group does store a map of key/value where key is the name of the variable, and the value is a variable. If you do not specify a name for a variable the name is ' default '. In the following example the first task does write 'hello world!' into the variable, and the second task does evaluate the value from the first task. Of course the second one write into the same variable its output since also there no name has been specified. --- taskgroups: - title: test tasks: - type: docker-container title: a simple example 1 code: echo \"hello world!\" docker-image: debian - type: dockier-container title: a simple example 2 code: echo \"{{ variables.default.value }}\" docker-image: debian In addition, you can evaluate the model if you have one. --- model: description: some description taskgroups: - title: test tasks: - type: docker-container title: a simple example 1 code: echo \"{{ model.attributest.description }}\" docker-image: debian The rules on how to access the individual elements of a model are explained here .","title":"Docker container task"},{"location":"docker-container/#docker-container-task","text":"This doesn't intend to explain Docker. Please refer to official Docker documentation for details on it. It's about the Docker container task. However a few things to mention here: Docker is an external tool that must exist otherwise you cannot use the task; even more the Hyperion tool will throw an error when the Docker tool has not been found. The default is to run Docker container with Unix images. On Windows you are able to switch to Windows container so you could run Windows batch code inside the Docker container. Usually you can switch to either use the one paltform or the other platform but not both at same time. From documentation, it seems an experimental feature that can be turned on allowing you to specify the parameter --platform with the values windows or unix so you could use both at same time. Since it is experimental and I cannot rely on yet that this is turned on by default I don't generate that parameter; means you cannot use both at same time for now. Also on Windows you have to be aware that sharing a drive is to be adjusted in the settings of Docker. Be aware that right now Hyperion differs two mounts which are currently done automatically: the mount of the current working directory (as /work) the mount of the path usually used for generating temporary files and folders by the standard Java API. At least it means you might have to allow more than one Windows drive to be shared with the Docker container . Since you probably want to run Hyperion processing automatically it is advisable to adjust this in advance otherwise the Docker process is trying to ask you via Dialog.","title":"Docker container task"},{"location":"docker-container/#the-minimal-example","text":"It's really easy and doesn't differ much from other task. Following details: The parameter image-name is required and should be the name of the Docker image. The parameter imager-version is optional and should be the version of the Docker image. If not specified the version is set to latest . The parameter platform is optional and can be either windows or unix . If not specified the platform is set to unix . It does have the effect that the generated temporary script - that will be executed by the Docker container - is either passed to cmd /c or sh -c . As already mentioned you cannot use both platforms in one document since --platform is not yet generated. So you have to decide which platform Docker should use by switching to it manually. Once the experimental status goes away that might change. --- taskgroups: - title: test tasks: - type: docker-container code: echo \"hello world!\" image-name: debian","title":"The minimal example"},{"location":"docker-container/#minimal-example-with-tags","text":"The application can be called with the repeatable option --tag. Specifying the those filter task will be executed only contain those tags. Task with other tags or even without any tags will be ignored then. --- taskgroups: - title: test tasks: - type: docker-container code: echo \"hello world!\" image-name: debian tags: - simple - example","title":"Minimal example with tags"},{"location":"docker-container/#example-with-variable","text":"The example with variable shows how to use the variable to extract information. It's exactly the same way as it does work for other tasks. You can specify the regex for filtering and - if required - the regex group; the default group is 0. --- taskgroups: - title: test tasks: - type: docker-container title: a simple example code: echo \"---> this is a demo <---\" image-name: debian variable: name: test2 regex: \">(.*)<\" group: 1","title":"Example with variable"},{"location":"docker-container/#example-with-templating","text":"The task group does store a map of key/value where key is the name of the variable, and the value is a variable. If you do not specify a name for a variable the name is ' default '. In the following example the first task does write 'hello world!' into the variable, and the second task does evaluate the value from the first task. Of course the second one write into the same variable its output since also there no name has been specified. --- taskgroups: - title: test tasks: - type: docker-container title: a simple example 1 code: echo \"hello world!\" docker-image: debian - type: dockier-container title: a simple example 2 code: echo \"{{ variables.default.value }}\" docker-image: debian In addition, you can evaluate the model if you have one. --- model: description: some description taskgroups: - title: test tasks: - type: docker-container title: a simple example 1 code: echo \"{{ model.attributest.description }}\" docker-image: debian The rules on how to access the individual elements of a model are explained here .","title":"Example with templating"},{"location":"groovy/","text":"Groovy task This page doesn't intend to explain Groovy. So please refer to official Groovy documentation for details on it. It's about the Groovy task. Minimal example The minimal example does not require a variable but the task does have one (always) with the name ' default '. The default regex is the whole text, and the default group is 0. --- taskgroups: - title: test tasks: - type: groovy code: println 'hello world!' Minimal example with tags The application can be called with the repeatable option --tag. Specifying the those filter task will be executed only contain those tags. Task with other tags or even without any tags will be ignored then. --- taskgroups: - title: test tasks: - type: groovy code: println 'hello world!' tags: - simple - example Example with variable The example with variable shows how to use the variable to extract information. It's exactly the same way as it does work for other tasks. You can specify the regex for filtering and - if required - the regex group; the default group is 0. --- taskgroups: - title: test tasks: - type: groovy title: a simple example code: println '---> this is a demo <---' variable: name: test2 regex: \">(.*)<\" group: 1 Example with templating The task group does store a map of key/value where key is the name of the variable, and the value is a variable. If you do not specify a name for a variable the name is ' default '. In the following example the first task does write 'hello world!' into the variable, and the second task does evaluate the value from the first task. Of course the second one write into the same variable its output since also there no name has been specified. --- taskgroups: - title: test tasks: - type: groovy title: a simple example 1 code: println 'hello world!' - type: groovy title: a simple example 2 code: println '{{ variables.default.value }}' In addition, you can evaluate the model if you have one. --- model: description: some description taskgroups: - title: test tasks: - type: groovy title: a simple example 1 code: println '{{ model.attributest.description }}' The rules on how to access the individual elements of a model are explained here .","title":"Groovy task"},{"location":"groovy/#groovy-task","text":"This page doesn't intend to explain Groovy. So please refer to official Groovy documentation for details on it. It's about the Groovy task.","title":"Groovy task"},{"location":"groovy/#minimal-example","text":"The minimal example does not require a variable but the task does have one (always) with the name ' default '. The default regex is the whole text, and the default group is 0. --- taskgroups: - title: test tasks: - type: groovy code: println 'hello world!'","title":"Minimal example"},{"location":"groovy/#minimal-example-with-tags","text":"The application can be called with the repeatable option --tag. Specifying the those filter task will be executed only contain those tags. Task with other tags or even without any tags will be ignored then. --- taskgroups: - title: test tasks: - type: groovy code: println 'hello world!' tags: - simple - example","title":"Minimal example with tags"},{"location":"groovy/#example-with-variable","text":"The example with variable shows how to use the variable to extract information. It's exactly the same way as it does work for other tasks. You can specify the regex for filtering and - if required - the regex group; the default group is 0. --- taskgroups: - title: test tasks: - type: groovy title: a simple example code: println '---> this is a demo <---' variable: name: test2 regex: \">(.*)<\" group: 1","title":"Example with variable"},{"location":"groovy/#example-with-templating","text":"The task group does store a map of key/value where key is the name of the variable, and the value is a variable. If you do not specify a name for a variable the name is ' default '. In the following example the first task does write 'hello world!' into the variable, and the second task does evaluate the value from the first task. Of course the second one write into the same variable its output since also there no name has been specified. --- taskgroups: - title: test tasks: - type: groovy title: a simple example 1 code: println 'hello world!' - type: groovy title: a simple example 2 code: println '{{ variables.default.value }}' In addition, you can evaluate the model if you have one. --- model: description: some description taskgroups: - title: test tasks: - type: groovy title: a simple example 1 code: println '{{ model.attributest.description }}' The rules on how to access the individual elements of a model are explained here .","title":"Example with templating"},{"location":"hyperion/","text":"Application Introduction The hyperion tool allows processing a YAML document with tasks. There can be many tasks like: Powershell (functional on Windows only) Batch (functional on Windows only) Groovy (all platforms because: embedded) JShell (all platforms because: embedded) That's the current list and will be updated when new tasks will be added. Command line interface The current command line options look like following: java -jar hyperion-1.0.0-SNAPSHOT.jar [global options] [command [command options]] version: 1.0.0-SNAPSHOT, build timestamp: 2021-05-20 03:48 author: Thomas Lehmann <thomas.lehmann.private@gmail.com> Global options: -h, --help - displaying this help --third-party - displaying used 3rd party libraries -t<str>, --tag=<str> - provide tag to filter tasks [repeatable] List of available commands: run - Running one document with tasks to be processed Options for command 'run': -f<path>, --file=<path> - Document with tasks to be processed [required] Also those help should be good enough to help on usage here a few notes: if you use --help you get the help. However, if you would also specify the command \"run\" you are forced to specify the path of the document too. Global options have to be specified before a command otherwise options would be interpreted as option related to a command and --help would be unknown then. You can specify one command only. Specifying a tag all tasks will run that have that tag only. Tasks with other tags or even without tags will be ignored.","title":"Application"},{"location":"hyperion/#application","text":"","title":"Application"},{"location":"hyperion/#introduction","text":"The hyperion tool allows processing a YAML document with tasks. There can be many tasks like: Powershell (functional on Windows only) Batch (functional on Windows only) Groovy (all platforms because: embedded) JShell (all platforms because: embedded) That's the current list and will be updated when new tasks will be added.","title":"Introduction"},{"location":"hyperion/#command-line-interface","text":"The current command line options look like following: java -jar hyperion-1.0.0-SNAPSHOT.jar [global options] [command [command options]] version: 1.0.0-SNAPSHOT, build timestamp: 2021-05-20 03:48 author: Thomas Lehmann <thomas.lehmann.private@gmail.com> Global options: -h, --help - displaying this help --third-party - displaying used 3rd party libraries -t<str>, --tag=<str> - provide tag to filter tasks [repeatable] List of available commands: run - Running one document with tasks to be processed Options for command 'run': -f<path>, --file=<path> - Document with tasks to be processed [required] Also those help should be good enough to help on usage here a few notes: if you use --help you get the help. However, if you would also specify the command \"run\" you are forced to specify the path of the document too. Global options have to be specified before a command otherwise options would be interpreted as option related to a command and --help would be unknown then. You can specify one command only. Specifying a tag all tasks will run that have that tag only. Tasks with other tags or even without tags will be ignored.","title":"Command line interface"},{"location":"junit5/","text":"JUnit5 The setup of Junit5 is explained here: Build . Default test methods There is not much to say since the annotation @Test is the same as for Junit4. However one fact is important: If you use @ParameterizedTest you cannot use @Test . Assertions The assertions of Junit5 are a lot to feel comfortable; after here some of them I have used: Assertion Meaning Context assertEquals Comparing two things to be equal values assertNotEquals Comparing two things to be unequal values assertTrue Verify that a condition evaluates to true condition/state assertFalse Verify that a condition evaluates to false condition/state assertNull Verify that an instance of something is null instance assertNotNull Verify that an instance of something is not null instance assertThrows Verify that a concrete exception has been thrown exception assertDoesNotThrow Verify that no exception is thrown. exception assumeTrue When condition is false the test is marked as ignored run/ignore test Note Each variant is provided a second one where you can provide a helpful message that is shown when the assertion is thrown. Note The assertThrows also provides the throwable that you additional can verify that the concrete message is thrown or whatever information you have passed to your exception. Parameterized tests Parameterized tests are a nice way to write a test method once calling it several times for different data input. In the list of tests each variant appears individually given you a clear idea which of the variant has failed. /** * Testing validation of the long name. * * @param bExpectedToFail when true then expected to fail. * @param strValue value for long name. * @param strMessage hint for the case the assertion does fail. */ @ParameterizedTest( name = \"test long name - #{index} expected to fail={0}, value={1}, message={2}\") @MethodSource(\"provideLongNameValidationTestData\") public void testLongNameValidation( final boolean bExpectedToFail, final String strValue, final String strMessage) { // setup of builder final var builder = CliOption.builder(); builder.setShortName(\"x\"); builder.setDescription(\"test\"); builder.setLongName(strValue); if (bExpectedToFail) { assertThrows(CliException.class, builder::build, strMessage); } else { assertDoesNotThrow(builder::build, strMessage); } } The given code is taken from Hyperion and you can see following: The annotation @ParametrerizedTest with the name value specifying how the test is displayed in the IDE. The curly braces are substituted by the values passes as parameters to the test function. The {index} is a special parameter to allow the visualize the nth call of the test method. The annotation @MethodSource is to specify a static method that does provide the test data. For being able to control how the assertion should work a boolean is passed as well telling the method what kind of assertion is wanted. In given example there is an exception thrown when the test is expected to fail otherwise it will be verified that no exception is thrown when test is expected to succeed. Note It's to say that the visualization of the parameterized test does not necessarily work on all IDE. That's why I have been switching to Intellij where it is working well. Note The annotation @DisplayName doesn't work well in the IDE (for now) on the test method; that's why I did place a name in front of the index. However it has to be placed on the class otherwise the Maven build shows null instead of the class name. The following code is the relating function providing the test data: /** * Test data for long name validation. * * @return test data. */ private static Stream<Arguments> provideLongNameValidationTestData() { //CHECKSTYLE.OFF: MultipleStringLiterals - ok here. return Stream.of( Arguments.of(true, null, \"cannot be null\"), Arguments.of(true, \"FILE\", \"cannot be uppercase letters\"), Arguments.of(true, \"f\", \"too short\"), Arguments.of(true, \"abcdefghijklmnop\", \"too long\"), Arguments.of(false, \"abcdefghijklmno\", \"maximum length for one subname\"), Arguments.of(false, \"config-file\", \"two valid sub names\"), Arguments.of(false, \"config-file-path\", \"three valid sub names\"), Arguments.of(true, \"the-config-file-path\", \"limited to three sub names\"), Arguments.of(true, \"abcdefghijklmno-abcdefghijklmnop\", \"second subname too long\"), Arguments.of(true, \"abcdefghijklmno-a\", \"second subname too short\"), Arguments.of(true, \"abcdefghijklmno-abcdefghijklmno-abcdefghijklmnop\", \"third subname too long\"), Arguments.of(true, \"abcdefghijklmno-abcdefghijklmno-a\", \"third subname too short\"), Arguments.of(false, \"http2\", \"allows number at the end\"), Arguments.of(true, \"2http\", \"name cannot start with numbers\"), Arguments.of(false, \"ht2tp\", \"allows numbers in name\"), Arguments.of(true, \"abc!?-_[](),;.\", \"cannot be special characters\") ); //CHECKSTYLE.ON: MultipleStringLiterals } Following information should be recognized: The function is - of course - private and it must be static . The return value is a Stream ! The function does return a Stream() something. Each entry enforces a call of the test method and the parameters for one call are Arguments.of() something. You don't need to but I organized to have the explaining message as one parameter. It appears in the list of tests as parameters as well as it is shown for the case that the test does fail because the message is passed to the. How it looks like in an IDE Assuming You might have the problem that a test depends on a certain setup of the system. Let's say you do not have Docker installed on your system then this test detects that and the concrete assertion will automatically mark the tests as ignored. @Test public void testDockerForTargetUnix() { assumeTrue(Capabilities.hasDocker()); // test code } OS specific tests There are test that can run on specific systems only. JUnit5 is capable to detect the system and you can use the annotation @EnabledOnOs to specify on which system the test should run. @DisplayName(\"Testing UnixShellTask\") @EnabledOnOs({OS.LINUX, OS.MAC}) public class UnixShellTaskTest { // test code } and @DisplayName(\"Testing WindowsBatchTask\") @EnabledOnOs(OS.WINDOWS) public class WindowsBatchTaskTest { // test code } Code Coverage Also explained in Build the awareness should here be raised that unit tests running on multiple environments and multiple platforms might lead to multiple coverage results. On Windows the class UnixShellTask is not tested (as an example). There for you can organize a profile which - at least - allows you to have different coverage limits depending on the platform. Order of test methods It's not obvious but there is an algorithm defining an order. However tests should be independent and therefor a random order is probably a better solution: @DisplayName(\"Testing of CliOption class\") @TestMethodOrder(value = MethodOrderer.Random.class) public class CliOptionTest { // test code } Please note When a test fails the logging prints the seed that has been used to run the methods in random order that you are able to re-run the tests in same order when the problem did arrive. You have to set the property junit.jupiter.execution.order.random.seed then. It's also possible to define random order of test classes. That can be defined in the pom.xml at the surefire Maven plugin with the configuration option <runOrder>random</runOrder> .","title":"JUnit5"},{"location":"junit5/#junit5","text":"The setup of Junit5 is explained here: Build .","title":"JUnit5"},{"location":"junit5/#default-test-methods","text":"There is not much to say since the annotation @Test is the same as for Junit4. However one fact is important: If you use @ParameterizedTest you cannot use @Test .","title":"Default test methods"},{"location":"junit5/#assertions","text":"The assertions of Junit5 are a lot to feel comfortable; after here some of them I have used: Assertion Meaning Context assertEquals Comparing two things to be equal values assertNotEquals Comparing two things to be unequal values assertTrue Verify that a condition evaluates to true condition/state assertFalse Verify that a condition evaluates to false condition/state assertNull Verify that an instance of something is null instance assertNotNull Verify that an instance of something is not null instance assertThrows Verify that a concrete exception has been thrown exception assertDoesNotThrow Verify that no exception is thrown. exception assumeTrue When condition is false the test is marked as ignored run/ignore test Note Each variant is provided a second one where you can provide a helpful message that is shown when the assertion is thrown. Note The assertThrows also provides the throwable that you additional can verify that the concrete message is thrown or whatever information you have passed to your exception.","title":"Assertions"},{"location":"junit5/#parameterized-tests","text":"Parameterized tests are a nice way to write a test method once calling it several times for different data input. In the list of tests each variant appears individually given you a clear idea which of the variant has failed. /** * Testing validation of the long name. * * @param bExpectedToFail when true then expected to fail. * @param strValue value for long name. * @param strMessage hint for the case the assertion does fail. */ @ParameterizedTest( name = \"test long name - #{index} expected to fail={0}, value={1}, message={2}\") @MethodSource(\"provideLongNameValidationTestData\") public void testLongNameValidation( final boolean bExpectedToFail, final String strValue, final String strMessage) { // setup of builder final var builder = CliOption.builder(); builder.setShortName(\"x\"); builder.setDescription(\"test\"); builder.setLongName(strValue); if (bExpectedToFail) { assertThrows(CliException.class, builder::build, strMessage); } else { assertDoesNotThrow(builder::build, strMessage); } } The given code is taken from Hyperion and you can see following: The annotation @ParametrerizedTest with the name value specifying how the test is displayed in the IDE. The curly braces are substituted by the values passes as parameters to the test function. The {index} is a special parameter to allow the visualize the nth call of the test method. The annotation @MethodSource is to specify a static method that does provide the test data. For being able to control how the assertion should work a boolean is passed as well telling the method what kind of assertion is wanted. In given example there is an exception thrown when the test is expected to fail otherwise it will be verified that no exception is thrown when test is expected to succeed. Note It's to say that the visualization of the parameterized test does not necessarily work on all IDE. That's why I have been switching to Intellij where it is working well. Note The annotation @DisplayName doesn't work well in the IDE (for now) on the test method; that's why I did place a name in front of the index. However it has to be placed on the class otherwise the Maven build shows null instead of the class name. The following code is the relating function providing the test data: /** * Test data for long name validation. * * @return test data. */ private static Stream<Arguments> provideLongNameValidationTestData() { //CHECKSTYLE.OFF: MultipleStringLiterals - ok here. return Stream.of( Arguments.of(true, null, \"cannot be null\"), Arguments.of(true, \"FILE\", \"cannot be uppercase letters\"), Arguments.of(true, \"f\", \"too short\"), Arguments.of(true, \"abcdefghijklmnop\", \"too long\"), Arguments.of(false, \"abcdefghijklmno\", \"maximum length for one subname\"), Arguments.of(false, \"config-file\", \"two valid sub names\"), Arguments.of(false, \"config-file-path\", \"three valid sub names\"), Arguments.of(true, \"the-config-file-path\", \"limited to three sub names\"), Arguments.of(true, \"abcdefghijklmno-abcdefghijklmnop\", \"second subname too long\"), Arguments.of(true, \"abcdefghijklmno-a\", \"second subname too short\"), Arguments.of(true, \"abcdefghijklmno-abcdefghijklmno-abcdefghijklmnop\", \"third subname too long\"), Arguments.of(true, \"abcdefghijklmno-abcdefghijklmno-a\", \"third subname too short\"), Arguments.of(false, \"http2\", \"allows number at the end\"), Arguments.of(true, \"2http\", \"name cannot start with numbers\"), Arguments.of(false, \"ht2tp\", \"allows numbers in name\"), Arguments.of(true, \"abc!?-_[](),;.\", \"cannot be special characters\") ); //CHECKSTYLE.ON: MultipleStringLiterals } Following information should be recognized: The function is - of course - private and it must be static . The return value is a Stream ! The function does return a Stream() something. Each entry enforces a call of the test method and the parameters for one call are Arguments.of() something. You don't need to but I organized to have the explaining message as one parameter. It appears in the list of tests as parameters as well as it is shown for the case that the test does fail because the message is passed to the.","title":"Parameterized tests"},{"location":"junit5/#how-it-looks-like-in-an-ide","text":"","title":"How it looks like in an IDE"},{"location":"junit5/#assuming","text":"You might have the problem that a test depends on a certain setup of the system. Let's say you do not have Docker installed on your system then this test detects that and the concrete assertion will automatically mark the tests as ignored. @Test public void testDockerForTargetUnix() { assumeTrue(Capabilities.hasDocker()); // test code }","title":"Assuming"},{"location":"junit5/#os-specific-tests","text":"There are test that can run on specific systems only. JUnit5 is capable to detect the system and you can use the annotation @EnabledOnOs to specify on which system the test should run. @DisplayName(\"Testing UnixShellTask\") @EnabledOnOs({OS.LINUX, OS.MAC}) public class UnixShellTaskTest { // test code } and @DisplayName(\"Testing WindowsBatchTask\") @EnabledOnOs(OS.WINDOWS) public class WindowsBatchTaskTest { // test code }","title":"OS specific tests"},{"location":"junit5/#code-coverage","text":"Also explained in Build the awareness should here be raised that unit tests running on multiple environments and multiple platforms might lead to multiple coverage results. On Windows the class UnixShellTask is not tested (as an example). There for you can organize a profile which - at least - allows you to have different coverage limits depending on the platform.","title":"Code Coverage"},{"location":"junit5/#order-of-test-methods","text":"It's not obvious but there is an algorithm defining an order. However tests should be independent and therefor a random order is probably a better solution: @DisplayName(\"Testing of CliOption class\") @TestMethodOrder(value = MethodOrderer.Random.class) public class CliOptionTest { // test code } Please note When a test fails the logging prints the seed that has been used to run the methods in random order that you are able to re-run the tests in same order when the problem did arrive. You have to set the property junit.jupiter.execution.order.random.seed then. It's also possible to define random order of test classes. That can be defined in the pom.xml at the surefire Maven plugin with the configuration option <runOrder>random</runOrder> .","title":"Order of test methods"},{"location":"matrix/","text":"Matrix Example --- matrix: - title: first run parameters: description: the first run sayHelloWorldCount: 3 - title: second run parameters: description: the second run sayHelloWorldCount: 2 taskgroups: - title: test group one tasks: - type: groovy title: running a Groovy task code: | println 'Groovy:{{ matrix.description }}' for (int ix = 1; ix <= {{ matrix.sayHelloWorldCount }}; ++ix) { println 'hello world ' + ix + '!' } Setup A matrix starts with the element matrix placed on same level as taskgroups. A matrix is a list. Each matrix item has two fields: title and parameters . The value for parameters is a key/value map (keys and values are interpreted as strings). Behaviour For each matrix item all existing task groups are running again. All variables stored in a previous run (per task group) are dropped.","title":"Matrix"},{"location":"matrix/#matrix","text":"","title":"Matrix"},{"location":"matrix/#example","text":"--- matrix: - title: first run parameters: description: the first run sayHelloWorldCount: 3 - title: second run parameters: description: the second run sayHelloWorldCount: 2 taskgroups: - title: test group one tasks: - type: groovy title: running a Groovy task code: | println 'Groovy:{{ matrix.description }}' for (int ix = 1; ix <= {{ matrix.sayHelloWorldCount }}; ++ix) { println 'hello world ' + ix + '!' }","title":"Example"},{"location":"matrix/#setup","text":"A matrix starts with the element matrix placed on same level as taskgroups. A matrix is a list. Each matrix item has two fields: title and parameters . The value for parameters is a key/value map (keys and values are interpreted as strings).","title":"Setup"},{"location":"matrix/#behaviour","text":"For each matrix item all existing task groups are running again. All variables stored in a previous run (per task group) are dropped.","title":"Behaviour"},{"location":"mkdocs/","text":"Mkdocs Installation It requires Python. pip install mkdocs mkdocs-bootswatch mkdocs-graphviz pymdown-extensions mkdocs-mermaid2-plugin Configuration The configuration of the project is defined in the mkdocs.yml in the root of the repository. At the top you define the meta data of the project like name of the project author of the project Url of the Github pages where these site will be located later on The url of the Github repository. In the middle section you define the navigation: With Home the main page is define which you see first. With Index you get a menu \"Index\" in the top bar and all sub menu items are those ones listed unter the index entry. At the bottom there are two sections: theme is for the look and feel. Therefore the mkdocs-bootswatch is needed. markdown_extensions are markdown extensions for rendering: mkdocs_graphviz is for rendering Graphviz syntax as SVG. admonition is for special note boxes. footnotes allows writing footnotes 1 pymdownx.tilde for strikethrough with ~~strikethrough~~ pymdownx.caret pymdownx.mark for marked with ==marked== pymdownx.magiclink for auto creation of links used in markdown code. plugins for plugins like: mkdocs-mermaid2-plugin for rendering Mermaid diagrams. Graphviz Example Following simple example (you have to add dot behind the first three backticks): ``` digraph D { A -> B; } ``` produces Special note boxes Please Note Some note. You have to choose the right indent Attention Some warning. Please don't ... Problem You are in trouble if ... generated by !!! note \"Please Note\" Some note. You have to choose the right indent !!! warning \"Attention\" Some warning. Please don't ... !!! error \"Problem\" You are in trouble if ... Mermaid example graph LR; A--> B & C & D; B--> A & E; C--> A & E; D--> A & E; E--> B & C & D; generated by ```mermaid graph LR; A--> B & C & D; B--> A & E; C--> A & E; D--> A & E; E--> B & C & D; ``` Testing It does build the site and after that you can open your browser at http://localhost:8000 to see the result. Changes to known Markdown files will be recognized, so you just have to refresh your Browser to see the results. mkdocs serve Deploying Later on it should be done automatically via Github workflow with a Github action but for now I'm doing it on a gh-pages branch manually by copying the content of the site folder - generates by mkdocs build - into that branch. Links https://gitlab.com/rodrigo.schwencke/mkdocs-graphviz https://squidfunk.github.io/mkdocs-material/reference/admonitions https://squidfunk.github.io/mkdocs-material/reference/footnotes/ https://facelessuser.github.io/pymdown-extensions/extensions/magiclink/ This is footnote one \u21a9","title":"Mkdocs"},{"location":"mkdocs/#mkdocs","text":"","title":"Mkdocs"},{"location":"mkdocs/#installation","text":"It requires Python. pip install mkdocs mkdocs-bootswatch mkdocs-graphviz pymdown-extensions mkdocs-mermaid2-plugin","title":"Installation"},{"location":"mkdocs/#configuration","text":"The configuration of the project is defined in the mkdocs.yml in the root of the repository. At the top you define the meta data of the project like name of the project author of the project Url of the Github pages where these site will be located later on The url of the Github repository. In the middle section you define the navigation: With Home the main page is define which you see first. With Index you get a menu \"Index\" in the top bar and all sub menu items are those ones listed unter the index entry. At the bottom there are two sections: theme is for the look and feel. Therefore the mkdocs-bootswatch is needed. markdown_extensions are markdown extensions for rendering: mkdocs_graphviz is for rendering Graphviz syntax as SVG. admonition is for special note boxes. footnotes allows writing footnotes 1 pymdownx.tilde for strikethrough with ~~strikethrough~~ pymdownx.caret pymdownx.mark for marked with ==marked== pymdownx.magiclink for auto creation of links used in markdown code. plugins for plugins like: mkdocs-mermaid2-plugin for rendering Mermaid diagrams.","title":"Configuration"},{"location":"mkdocs/#graphviz-example","text":"Following simple example (you have to add dot behind the first three backticks): ``` digraph D { A -> B; } ``` produces","title":"Graphviz Example"},{"location":"mkdocs/#special-note-boxes","text":"Please Note Some note. You have to choose the right indent Attention Some warning. Please don't ... Problem You are in trouble if ... generated by !!! note \"Please Note\" Some note. You have to choose the right indent !!! warning \"Attention\" Some warning. Please don't ... !!! error \"Problem\" You are in trouble if ...","title":"Special note boxes"},{"location":"mkdocs/#mermaid-example","text":"graph LR; A--> B & C & D; B--> A & E; C--> A & E; D--> A & E; E--> B & C & D; generated by ```mermaid graph LR; A--> B & C & D; B--> A & E; C--> A & E; D--> A & E; E--> B & C & D; ```","title":"Mermaid example"},{"location":"mkdocs/#testing","text":"It does build the site and after that you can open your browser at http://localhost:8000 to see the result. Changes to known Markdown files will be recognized, so you just have to refresh your Browser to see the results. mkdocs serve","title":"Testing"},{"location":"mkdocs/#deploying","text":"Later on it should be done automatically via Github workflow with a Github action but for now I'm doing it on a gh-pages branch manually by copying the content of the site folder - generates by mkdocs build - into that branch.","title":"Deploying"},{"location":"mkdocs/#links","text":"https://gitlab.com/rodrigo.schwencke/mkdocs-graphviz https://squidfunk.github.io/mkdocs-material/reference/admonitions https://squidfunk.github.io/mkdocs-material/reference/footnotes/ https://facelessuser.github.io/pymdown-extensions/extensions/magiclink/ This is footnote one \u21a9","title":"Links"},{"location":"shell/","text":"Shell task This page doesn't intend to explain Unix shell. So please refer to official Unix shell documentation for details on it. It's about the Unix shell task. Minimal example The minimal example does not require a variable but the task does have one (always) with the name ' default '. The default regex is the whole text, and the default group is 0. --- taskgroups: - title: test tasks: - type: shell code: echo \"hello world!\" Minimal example with tags The application can be called with the repeatable option --tag. Specifying the those filter task will be executed only contain those tags. Task with other tags or even without any tags will be ignored then. --- taskgroups: - title: test tasks: - type: shell code: echo \"hello world!\" tags: - simple - example Example with variable The example with variable shows how to use the variable to extract information. It's exactly the same way as it does work for other tasks. You can specify the regex for filtering and - if required - the regex group; the default group is 0. --- taskgroups: - title: test tasks: - type: shell title: a simple example code: echo \"---> this is a demo <---\" variable: name: test2 regex: \">(.*)<\" group: 1 Example with templating The task group does store a map of key/value where key is the name of the variable, and the value is a variable. If you do not specify a name for a variable the name is ' default '. In the following example the first task does write 'hello world!' into the variable, and the second task does evaluate the value from the first task. Of course the second one write into the same variable its output since also there no name has been specified. --- taskgroups: - title: test tasks: - type: shell title: a simple example 1 code: echo \"hello world!\" - type: shell title: a simple example 2 code: echo \"{{ variables.default.value }}\" In addition, you can evaluate the model if you have one. --- model: description: some description taskgroups: - title: test tasks: - type: shell title: a simple example 1 code: echo \"{{ model.attributest.description }}\" The rules on how to access the individual elements of a model are explained here .","title":"Shell task"},{"location":"shell/#shell-task","text":"This page doesn't intend to explain Unix shell. So please refer to official Unix shell documentation for details on it. It's about the Unix shell task.","title":"Shell task"},{"location":"shell/#minimal-example","text":"The minimal example does not require a variable but the task does have one (always) with the name ' default '. The default regex is the whole text, and the default group is 0. --- taskgroups: - title: test tasks: - type: shell code: echo \"hello world!\"","title":"Minimal example"},{"location":"shell/#minimal-example-with-tags","text":"The application can be called with the repeatable option --tag. Specifying the those filter task will be executed only contain those tags. Task with other tags or even without any tags will be ignored then. --- taskgroups: - title: test tasks: - type: shell code: echo \"hello world!\" tags: - simple - example","title":"Minimal example with tags"},{"location":"shell/#example-with-variable","text":"The example with variable shows how to use the variable to extract information. It's exactly the same way as it does work for other tasks. You can specify the regex for filtering and - if required - the regex group; the default group is 0. --- taskgroups: - title: test tasks: - type: shell title: a simple example code: echo \"---> this is a demo <---\" variable: name: test2 regex: \">(.*)<\" group: 1","title":"Example with variable"},{"location":"shell/#example-with-templating","text":"The task group does store a map of key/value where key is the name of the variable, and the value is a variable. If you do not specify a name for a variable the name is ' default '. In the following example the first task does write 'hello world!' into the variable, and the second task does evaluate the value from the first task. Of course the second one write into the same variable its output since also there no name has been specified. --- taskgroups: - title: test tasks: - type: shell title: a simple example 1 code: echo \"hello world!\" - type: shell title: a simple example 2 code: echo \"{{ variables.default.value }}\" In addition, you can evaluate the model if you have one. --- model: description: some description taskgroups: - title: test tasks: - type: shell title: a simple example 1 code: echo \"{{ model.attributest.description }}\" The rules on how to access the individual elements of a model are explained here .","title":"Example with templating"},{"location":"taskgroup/","text":"Taskgroup A task group basically has three information: a required title an optional boolean flag indicating whether tasks should run in parallel or in order a required list of tasks Minimal example The three tasks in this example are running one after the other in the specified order . --- taskgroups: - title: test tasks: - type: groovy code: println 'hello world 1!' - type: groovy code: println 'hello world 2!' - type: groovy code: println 'hello world 3!' Note Also no variables have been specified the variables are there. The name of those variables is then \"default\". You are able to evaluate the value of a previously set variable with that name using templating with following expression: {{ variables.default.value }} . See also : Templating Running tasks in parallel The three tasks in this example are running in parallel. The output will be the inverse order of what has been specified because of the sleep statements. --- taskgroups: - title: test parallel: true tasks: - type: groovy code: | sleep(2000) println 'hello world 1!' - type: groovy code: | sleep(1000) println 'hello world 2!' - type: groovy code: | println 'hello world 3!' Warning Also the variables are not specified here they are given. It means that the stdout of the tasks is always stored. If you don't specify the variable yourself then name of the task variable is always \"default\". Running tasks in parallel the situation is unfavorable since you cannot always rely on which value will be written into the variable except you control the order of the execution like shown in the example. For that situation a warning is logged by the tool to inform you that you have duplicate variable names. Of course this also will happen if you specify the same name for variables yourself multiple times.","title":"Taskgroup"},{"location":"taskgroup/#taskgroup","text":"A task group basically has three information: a required title an optional boolean flag indicating whether tasks should run in parallel or in order a required list of tasks","title":"Taskgroup"},{"location":"taskgroup/#minimal-example","text":"The three tasks in this example are running one after the other in the specified order . --- taskgroups: - title: test tasks: - type: groovy code: println 'hello world 1!' - type: groovy code: println 'hello world 2!' - type: groovy code: println 'hello world 3!' Note Also no variables have been specified the variables are there. The name of those variables is then \"default\". You are able to evaluate the value of a previously set variable with that name using templating with following expression: {{ variables.default.value }} . See also : Templating","title":"Minimal example"},{"location":"taskgroup/#running-tasks-in-parallel","text":"The three tasks in this example are running in parallel. The output will be the inverse order of what has been specified because of the sleep statements. --- taskgroups: - title: test parallel: true tasks: - type: groovy code: | sleep(2000) println 'hello world 1!' - type: groovy code: | sleep(1000) println 'hello world 2!' - type: groovy code: | println 'hello world 3!' Warning Also the variables are not specified here they are given. It means that the stdout of the tasks is always stored. If you don't specify the variable yourself then name of the task variable is always \"default\". Running tasks in parallel the situation is unfavorable since you cannot always rely on which value will be written into the variable except you control the order of the execution like shown in the example. For that situation a warning is logged by the tool to inform you that you have duplicate variable names. Of course this also will happen if you specify the same name for variables yourself multiple times.","title":"Running tasks in parallel"},{"location":"templating/","text":"Templating Introduction One of the most powerful feature of the Hyperion tool is the templating that allows you to the dynamic replacement in the code of the part. Hyperion offers currently two data sources: the model the task group variables The model is a kind of freestyle hierarchical structure you can define to model the required data when running your tasks. The task group variables are initially empty and filled whenever a task has finished successfully. Accessing the variables Assuming you missed defining a variable on a task the name of a variable is \"default\". You then can access the variable in your task code with {{ variables.default.value }} . Assuming you evaluate a special path in your task writing it to a named variable \"path\" the possible evaluation in the next task would be {{ variables.path.value }} . It depends on of course whether tasks are running ordered or in parallel whether one task can read a variable of a previous task. Even more it's unpredictable for parallel tasks with same names to know which value will be given when you access it. Accessing the model The model - once understood - is a great way to modularize your task code also allowing reuse. For the next examples a few explanations: attributes - the term means that the object behind stores for a key a value; of course the can be multiple keys. The value can be a string, a number, a boolean, a list or - again - a key/value object. values - the means a list. The value can be a string, a number, a boolean or a key/value object. --- model: description: this is a simple example Trying to access this description you have to write {{ model.attributes.description }} . --- model: subModel: description: this is a simple example Here the value you get with {{ model.attributes.subModel.attributes.description }} --- model: descriptions: - this is a simple example Here the value you get with {{ model.attributes.descriptions.values[0] }} . model: actions: - name: action A command: println 'hello world 1 !' Here the name and the command can be accessed this way: {{ model.attributes.actions.values[0].attributes.name }} {{ model.attributes.actions.values[0].attributes.command }} If you want to know more about how this works then please also read here: https://pebbletemplates.io/wiki/guide/basic-usage/ (it shows internal usage as well as what you can do with it) (Near) Future enhancements Matrix variables (a matrix runs all task groups again for a different set of variables) Defining task group variables in the document","title":"Templating"},{"location":"templating/#templating","text":"","title":"Templating"},{"location":"templating/#introduction","text":"One of the most powerful feature of the Hyperion tool is the templating that allows you to the dynamic replacement in the code of the part. Hyperion offers currently two data sources: the model the task group variables The model is a kind of freestyle hierarchical structure you can define to model the required data when running your tasks. The task group variables are initially empty and filled whenever a task has finished successfully.","title":"Introduction"},{"location":"templating/#accessing-the-variables","text":"Assuming you missed defining a variable on a task the name of a variable is \"default\". You then can access the variable in your task code with {{ variables.default.value }} . Assuming you evaluate a special path in your task writing it to a named variable \"path\" the possible evaluation in the next task would be {{ variables.path.value }} . It depends on of course whether tasks are running ordered or in parallel whether one task can read a variable of a previous task. Even more it's unpredictable for parallel tasks with same names to know which value will be given when you access it.","title":"Accessing the variables"},{"location":"templating/#accessing-the-model","text":"The model - once understood - is a great way to modularize your task code also allowing reuse. For the next examples a few explanations: attributes - the term means that the object behind stores for a key a value; of course the can be multiple keys. The value can be a string, a number, a boolean, a list or - again - a key/value object. values - the means a list. The value can be a string, a number, a boolean or a key/value object. --- model: description: this is a simple example Trying to access this description you have to write {{ model.attributes.description }} . --- model: subModel: description: this is a simple example Here the value you get with {{ model.attributes.subModel.attributes.description }} --- model: descriptions: - this is a simple example Here the value you get with {{ model.attributes.descriptions.values[0] }} . model: actions: - name: action A command: println 'hello world 1 !' Here the name and the command can be accessed this way: {{ model.attributes.actions.values[0].attributes.name }} {{ model.attributes.actions.values[0].attributes.command }} If you want to know more about how this works then please also read here: https://pebbletemplates.io/wiki/guide/basic-usage/ (it shows internal usage as well as what you can do with it)","title":"Accessing the model"},{"location":"templating/#near-future-enhancements","text":"Matrix variables (a matrix runs all task groups again for a different set of variables) Defining task group variables in the document","title":"(Near) Future enhancements"}]}